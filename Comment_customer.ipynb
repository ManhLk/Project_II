{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from pyvi import ViTokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN, Dropout, Convolution1D, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df=pd.read_excel(r'Data/negative_comment_student.xlsx')\n",
    "negative_df['Label'] = [0 for x in range(negative_df.shape[0])] \n",
    "negative_df = negative_df[['Opinion', 'Label']]\n",
    "positive_df=pd.read_excel(r'Data/positive_comment_student.xlsx')\n",
    "positive_df['Label'] = [1 for x in range(positive_df.shape[0])]\n",
    "positive_df = positive_df[['Opinion', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([negative_df,positive_df], axis=0)\n",
    "train.index = [i for i in range(train.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3961 entries, 0 to 3960\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Opinion  3961 non-null   object\n",
      " 1   Label    3961 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 92.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    \n",
    "    # Chuyển thành chữ thường \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Chuẩn hóa tiếng việt\n",
    "    replace_list={'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ', 'okey': ' ok ', 'ôkê': ' ok ', ' oki ': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n",
    "    ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ', 'cam on':u'cám ơn',u'cảm ơn':'cám ơn',\n",
    "    ' not ': u' không ',' khoong ': ' không ', u' kg ': u' không ','ko ': 'không', ' k ': u' không ',' kh ':u' không ',' kô ':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', ' ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',' k ':u' không ',u'chẳng':u'không',u'đéo':u'không'}\n",
    "    for k, v in replace_list.items():\n",
    "        text = text.replace(k, v)\n",
    "    \n",
    "    # Xóa icon\n",
    "    text = re.sub(r\"\\W\", \" \",text)\n",
    "    \n",
    "    # Xóa dấu câu\n",
    "    text = re.sub('['+string.punctuation+']', ' ', text)\n",
    "    \n",
    "    # Tokenizer\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = []\n",
    "for i in range(train.shape[0]):\n",
    "    new_sentence.append(pre_processing(train['Opinion'][i]))\n",
    "train['New_Opinion'] = new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, Kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMModel:\n",
    "    def __init__(self):\n",
    "        self.clf = self._init_pipeline()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _init_pipeline():\n",
    "        stopwords=('rằng', 'thì', 'mà', 'là', 'thế', 'à', 'ừ', 'vậy', 'như')\n",
    "        pipe_line = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(stop_words=stopwords)), # bag of words\n",
    "            (\"tfidf\", TfidfTransformer()), # tf-idf\n",
    "            (\"clf_svm\", SVC(kernel='linear', probability=True)) # svm kernel = 'linear'\n",
    "        ])\n",
    "        return pipe_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(train['New_Opinion'].values, train['Label'].values, test_size=.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9191002367797948\n",
      "Test accuracy: 0.7894073139974779\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVMModel().clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\",clf_svm.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", clf_svm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo Tokenizer\n",
    "tokenizer = Tokenizer(num_words= vocab_size, oov_token= oov_tok)\n",
    "\n",
    "# Đưa từ vào tokenizer để tạo từ điển\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Biến các câu train thành sequences\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "# Padding cho các train sequences\n",
    "x_train = pad_sequences(x_train, maxlen= max_length, padding=padding_type, truncating= trunc_type)\n",
    "\n",
    "# Biến các câu val thành sequences tương ứng\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "x_val = pad_sequences(x_val, maxlen= max_length, padding=padding_type, truncating= trunc_type)\n",
    "\n",
    "# Biến các câu test thành sequences tương ứng\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_test = pad_sequences(x_test, maxlen= max_length, padding=padding_type, truncating= trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 665,889\n",
      "Trainable params: 665,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=x_train.shape[1]))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.5112 - accuracy: 0.7695 - val_loss: 0.3854 - val_accuracy: 0.8360\n",
      "Epoch 2/4\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.3001 - accuracy: 0.8662 - val_loss: 0.3360 - val_accuracy: 0.8470\n",
      "Epoch 3/4\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.2185 - accuracy: 0.9112 - val_loss: 0.3339 - val_accuracy: 0.8565\n",
      "Epoch 4/4\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.1599 - accuracy: 0.9388 - val_loss: 0.4293 - val_accuracy: 0.8423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d3b143fb70>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4642 - accuracy: 0.8373\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
