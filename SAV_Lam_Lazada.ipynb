{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyvi import ViTokenizer \n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(r'Data\\data_lazada.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Đã nhận hàng nhanh chóng! Nhưng Side XXL mờ Sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giao hàng lâu. áo ko giống mẫu chụp. thất vọng</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Áo đẹp trong tầm giá, mỗi tội mình mua 2 cái đ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>áo đẹp lắm ạ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chuẩn y hình, đẹp ưng lắm luôn,cho shop 5sao</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label\n",
       "0  Đã nhận hàng nhanh chóng! Nhưng Side XXL mờ Sh...      0\n",
       "1     giao hàng lâu. áo ko giống mẫu chụp. thất vọng      0\n",
       "2  Áo đẹp trong tầm giá, mỗi tội mình mua 2 cái đ...      1\n",
       "3                                    áo đẹp lắm ạ      1\n",
       "4       chuẩn y hình, đẹp ưng lắm luôn,cho shop 5sao      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1171 entries, 0 to 1170\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  1171 non-null   object\n",
      " 1   Label     1171 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Positive(1) and Negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    666\n",
       "0    505\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sentiment = pd.value_counts(train['Label'])\n",
    "count_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    \n",
    "    # chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Xóa icon\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                   u\"\\U00002702-\\U000027B0\"\n",
    "                   u\"\\U000024C2-\\U0001F251\"\n",
    "                   u\"\\U0001f926-\\U0001f937\"\n",
    "                   u\"\\u200d\"\n",
    "                   u\"\\u2640-\\u2642\" \n",
    "                   \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Chuan hoa tieng viet, tieng anh, thuat ngu\n",
    "    replace_list={\n",
    "        'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n",
    "    'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n",
    "    'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
    "    'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
    "    'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
    "    #Chuẩn hóa 1 số sentiment words/English words\n",
    "    ':))': '  positive ', ':)': ' positive ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n",
    "    'okey': ' ok ', 'ôkê': ' ok ', ' oki ': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n",
    "    ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ', 'cam on':u'cám ơn',u'cảm ơn':'cám ơn',\n",
    "    ' not ': u' không ',' khoong ': ' không ', u' kg ': u' không ','ko ': 'không', ' k ': u' không ',' kh ':u' không ',' kô ':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', ' ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',' k ':u' không ',u'chẳng':u'không',u'đéo':u'không',\n",
    "    'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
    "    ' lol ': ' negative ',' cc ': ' negative ','cute': u' dễ thương ','huhu': ' negative ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', ' j ': u' gì ', '“': ' ',\n",
    "    ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
    "    'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u' positive ', 'store': u' cửa hàng ',\n",
    "    'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n",
    "    'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n",
    "    'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
    "    'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n",
    "    'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n",
    "    'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n",
    "    'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n",
    "    'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ', ' quả ng ': ' quảng ',\n",
    "    'dep': u' đẹp ',u'xầu':u'xấu',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u' qủa': u' quả', \n",
    "    ' iu ': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời', '><': u' positive ', \n",
    "    ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback ',\n",
    "    'qc':u'quảng cáo',u' éo ':' negative ',' bik ':' biết ',\n",
    "    #dưới 3* quy về 1*, trên 3* quy về 5*\n",
    "    '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ', '5 sao': '5star',\n",
    "    'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ', '3 sao':'5star','4 sao':'5star','1 sao':'1star',\n",
    "    '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ','1*':' 1star ', '2*':' 1star ','3*':' 5star ','4*':' 5star ','5*':' 5star '\n",
    "    }\n",
    "    for k, v in replace_list.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    #Xóa dấu câu linh tinh\n",
    "    text = re.sub('['+string.punctuation+']', ' ', text)\n",
    "\n",
    "    # Tokenizer\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    \n",
    "    _not = ['không', 'không thể' , 'chẳng', 'đéo', 'đếch', 'kém']\n",
    "    positive = ['5star', 'positive', 'ưng', 'hài_lòng', 'thích',  'ngon', 'tốt']\n",
    "    negative = ['1start', 'negative', 'lừa','thất_vọng', 'chán', 'hợp', 'xấu', 'lừa_đảo', 'rất kém','tệ', 'tồi_tệ']\n",
    "    txt_split = [txt.replace('_',' ') for txt in text.split()]\n",
    "    for i in range(len(txt_split)):\n",
    "        if txt_split[i] in _not:\n",
    "            if (i < len(txt_split)-1):\n",
    "                if txt_split[i+1] in positive:\n",
    "                    text = text.replace(txt_split[i]+' '+txt_split[i+1],'negative')\n",
    "                    txt_split[i]=txt_split[i+1]=''\n",
    "                elif txt_split[i+1] in negative:\n",
    "                    text = text.replace(txt_split[i]+' '+txt_split[i+1],'positive')\n",
    "                    txt_split[i]=txt_split[i+1]=''\n",
    "        else:\n",
    "            if txt_split[i] in negative:\n",
    "                text = text + ' negative'\n",
    "            elif txt_split[i] in positive:\n",
    "                text = text + ' positive'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Sentence = []\n",
    "for i in range(train.shape[0]):\n",
    "    New_Sentence.append(pre_processing(train['Sentence'][i]))\n",
    "train['New_Sentence'] = New_Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>New_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Đã nhận hàng nhanh chóng! Nhưng Side XXL mờ Sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>đã nhận hàng nhanh_chóng nhưng side xxl mờ cửa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giao hàng lâu. áo ko giống mẫu chụp. thất vọng</td>\n",
       "      <td>0</td>\n",
       "      <td>giao hàng lâu áo khônggiống mẫu chụp thất_vọng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Áo đẹp trong tầm giá, mỗi tội mình mua 2 cái đ...</td>\n",
       "      <td>1</td>\n",
       "      <td>áo đẹp trong tầm giá mỗi tội mình mua 2 cái đề...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>áo đẹp lắm ạ</td>\n",
       "      <td>1</td>\n",
       "      <td>áo đẹp lắm ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chuẩn y hình, đẹp ưng lắm luôn,cho shop 5sao</td>\n",
       "      <td>1</td>\n",
       "      <td>chuẩn_y hình đẹp ưng lắm luôn cho cửa_hàng 5st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label  \\\n",
       "0  Đã nhận hàng nhanh chóng! Nhưng Side XXL mờ Sh...      0   \n",
       "1     giao hàng lâu. áo ko giống mẫu chụp. thất vọng      0   \n",
       "2  Áo đẹp trong tầm giá, mỗi tội mình mua 2 cái đ...      1   \n",
       "3                                    áo đẹp lắm ạ      1   \n",
       "4       chuẩn y hình, đẹp ưng lắm luôn,cho shop 5sao      1   \n",
       "\n",
       "                                        New_Sentence  \n",
       "0  đã nhận hàng nhanh_chóng nhưng side xxl mờ cửa...  \n",
       "1     giao hàng lâu áo khônggiống mẫu chụp thất_vọng  \n",
       "2  áo đẹp trong tầm giá mỗi tội mình mua 2 cái đề...  \n",
       "3                                       áo đẹp lắm ạ  \n",
       "4  chuẩn_y hình đẹp ưng lắm luôn cho cửa_hàng 5st...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.loc[:,'New_Sentence'], train.loc[:,'Label'], test_size =.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=('rằng', 'thì', 'mà', 'là', 'thế', 'à', 'ừ', 'vậy', 'như')\n",
    "pipe_line = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(stop_words=stopwords)), # bag of words\n",
    "    (\"tfidf\", TfidfTransformer()), # tf-idf\n",
    "    (\"clf_svm\", SVC(kernel='linear', probability=True)) # svm kernel = 'linear'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = pipe_line.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9700854700854701\n",
      "Test accuracy: 0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\",clf_svm.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       109\n",
      "           1       0.93      0.91      0.92       126\n",
      "\n",
      "    accuracy                           0.91       235\n",
      "   macro avg       0.91      0.92      0.91       235\n",
      "weighted avg       0.92      0.91      0.91       235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_predict = clf_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
