{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def load_raw_data(self, filename, is_train=True):\n",
    "        ID = []\n",
    "        label = []\n",
    "        sentence = []\n",
    "        review = ''        \n",
    "        if is_train:\n",
    "            with open(filename, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('train_'):\n",
    "                        ID.append(line.replace('\\n',''))\n",
    "                    elif line[:-1].isdigit():\n",
    "                        review = review.replace('\\n',' ')\n",
    "                        review = ' '.join((review.lower()).split())\n",
    "                        sentence.append(review)\n",
    "                        review = ''\n",
    "                        label.append(int(line[:-1]))\n",
    "                    else:\n",
    "                        review = review +' '+ line\n",
    "        else:\n",
    "            with open(filename, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('test_'):\n",
    "                        review = review.replace('\\n',' ')\n",
    "                        review = ' '.join((review.lower()).split())\n",
    "                        sentence.append(review)\n",
    "                        review = ''\n",
    "                        ID.append(line.replace('\\n',''))\n",
    "                    else:\n",
    "                        review = review +' '+ line\n",
    "            review = review.replace('\\n',' ')\n",
    "            review = re.sub('['+string.punctuation+']', ' ', review)\n",
    "            review = ' '.join((review.lower()).split())\n",
    "            sentence.append(review)\n",
    "            del sentence[0]\n",
    "        return (ID, label, sentence)\n",
    "    \n",
    "    def pre_processing(self, text):\n",
    "        \n",
    "        # Xoa icon linh tinh\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                       u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                       u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                       u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                       u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                       u\"\\U00002702-\\U000027B0\"\n",
    "                       u\"\\U000024C2-\\U0001F251\"\n",
    "                       u\"\\U0001f926-\\U0001f937\"\n",
    "                       u\"\\u200d\"\n",
    "                       u\"\\u2640-\\u2642\" \n",
    "                       \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        \n",
    "        # Chuan hoa tieng viet, tieng anh, thuat ngu\n",
    "        replace_list={\n",
    "            'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n",
    "        'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n",
    "        'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
    "        'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
    "        'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
    "        #Chuẩn hóa 1 số sentiment words/English words\n",
    "        ':))': '  positive ', ':)': ' positive ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n",
    "        'okey': ' ok ', 'ôkê': ' ok ', ' oki ': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n",
    "        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ', 'cam on':u'cám ơn',u'cảm ơn':'cám ơn',\n",
    "        ' not ': u' không ',' khoong ': ' không ', u' kg ': u' không ','ko ': 'không', ' k ': u' không ',' kh ':u' không ',' kô ':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', ' ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',' k ':u' không ',u'chẳng':u'không',u'đéo':u'không',\n",
    "        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
    "        ' lol ': ' negative ',' cc ': ' negative ','cute': u' dễ thương ','huhu': ' negative ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', ' j ': u' gì ', '“': ' ',\n",
    "        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
    "        'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u' positive ', 'store': u' cửa hàng ',\n",
    "        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n",
    "        'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n",
    "        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
    "        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n",
    "        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n",
    "        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n",
    "        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n",
    "        'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ', ' quả ng ': ' quảng ',\n",
    "        'dep': u' đẹp ',u'xầu':u'xấu',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u' qủa': u' quả', \n",
    "        ' iu ': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời', '><': u' positive ', \n",
    "        ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback ',\n",
    "        'qc':u'quảng cáo',u' éo ':' negative ',' bik ':' biết ',\n",
    "        #dưới 3* quy về 1*, trên 3* quy về 5*\n",
    "        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ', '5 sao': '5star',\n",
    "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ', '3 sao':'5star','4 sao':'5star','1 sao':'1star',\n",
    "        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ','1*':' 1star ', '2*':' 1star ','3*':' 5star ','4*':' 5star ','5*':' 5star '\n",
    "        }\n",
    "        for k, v in replace_list.items():\n",
    "            text = text.replace(k, v)\n",
    "        \n",
    "        #Xóa dấu câu linh tinh\n",
    "        text = re.sub('['+string.punctuation+']', ' ', text)\n",
    "        \n",
    "        # Tokenizer\n",
    "        text = ViTokenizer.tokenize(text)\n",
    "        \n",
    "        _not = ['không', 'không thể' , 'chẳng', 'đéo', 'đếch', 'kém']\n",
    "        positive = ['5star', 'positive', 'ưng', 'hài lòng', 'thích',  'ngon', 'tốt']\n",
    "        negative = ['1start', 'negative', 'lừa','thất vọng', 'chán', 'hợp', 'xấu', 'lừa đảo', 'rất kém','tệ']\n",
    "        txt_split = [txt.replace('_',' ') for txt in text.split()]\n",
    "        for i in range(len(txt_split)):\n",
    "            if txt_split[i] in _not:\n",
    "                if (i < len(txt_split)-1):\n",
    "                    if txt_split[i+1] in positive:\n",
    "                        text = text.replace(txt_split[i]+' '+txt_split[i+1],'negative')\n",
    "                        txt_split[i]=txt_split[i+1]=''\n",
    "                    elif txt_split[i+1] in negative:\n",
    "                        text = text.replace(txt_split[i]+' '+txt_split[i+1],'positive')\n",
    "                        txt_split[i]=txt_split[i+1]=''\n",
    "            else:\n",
    "                if txt_split[i] in negative:\n",
    "                    text = text + ' negative'\n",
    "                elif txt_split[i] in positive:\n",
    "                    text = text + ' positive'\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def load_data(self, filename, is_train=True):\n",
    "        new_sentence = []\n",
    "        ID, Label, Sentence = self.load_raw_data(filename, is_train)\n",
    "        for i in range(len(Sentence)):\n",
    "            new_sentence.append(self.pre_processing(Sentence[i]))\n",
    "        return ID, Label, Sentence, new_sentence\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_to_excel(data_frame,filename_save, sheet_name='Sheet1'):\n",
    "        filename_save = str(filename_save)+'.xlsx'\n",
    "        excel_save = pd.ExcelWriter(filename_save, engine='xlsxwriter')\n",
    "        data_frame.to_excel(excel_save, sheet_name=sheet_name)\n",
    "        excel_save.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesModel:\n",
    "    def __init__(self):\n",
    "        self.clf = self._init_pipeline()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_pipeline():\n",
    "        stopwords=('rằng', 'thì', 'mà', 'là', 'thế', 'à', 'ừ', 'vậy', 'như')\n",
    "        pipe_line = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(stop_words=stopwords)), # bag of words\n",
    "            (\"tfidf\", TfidfTransformer()), # tf-idf\n",
    "            (\"clf\", MultinomialNB()) # navie bayes models\n",
    "        ])\n",
    "        return pipe_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine - kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMModel:\n",
    "    def __init__(self):\n",
    "        self.clf = self._init_pipeline()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _init_pipeline():\n",
    "        stopwords=('rằng', 'thì', 'mà', 'là', 'thế', 'à', 'ừ', 'vậy', 'như')\n",
    "        pipe_line = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(stop_words=stopwords)), # bag of words\n",
    "            (\"tfidf\", TfidfTransformer()), # tf-idf\n",
    "            (\"clf_svm\", SVC(kernel='linear', probability=True)) # svm kernel = 'linear'\n",
    "        ])\n",
    "        return pipe_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID, Label, Sentence, New_Sentence = Data().load_data(r'D:\\Documents\\Đồ án 2\\Sentiment Analysis\\Sentiment data\\vibo\\train.crash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame([ID, Label, Sentence, New_Sentence]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['ID', 'Label', 'Sentence', 'New_Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>New_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>0</td>\n",
       "      <td>\"dung dc sp tot cam on shop đóng gói sản phẩm ...</td>\n",
       "      <td>dung được sản_phẩm tốt cám_ơn cửa_hàng đóng_gó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>\" chất lượng sản phẩm tuyệt vời . son mịn nhưn...</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời son mịn nhưng kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>\" chất lượng sản phẩm tuyệt vời nhưng k có hộp...</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời nhưng không có h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>1</td>\n",
       "      <td>\":(( mình hơi thất vọng 1 chút vì mình đã kỳ v...</td>\n",
       "      <td>mình hơi thất_vọng 1 chút vì mình đã kỳ_vọng c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>1</td>\n",
       "      <td>\"lần trước mình mua áo gió màu hồng rất ok mà ...</td>\n",
       "      <td>lần trước mình mua áo_gió màu hồng rất ok mà đ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_000005</td>\n",
       "      <td>0</td>\n",
       "      <td>\" chất lượng sản phẩm tuyệt vời có điều không ...</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời có_điều không cứ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_000006</td>\n",
       "      <td>0</td>\n",
       "      <td>\"đã nhận đc hàng rất nhanh mới đặt buổi tối mà...</td>\n",
       "      <td>đã nhận được hàng rất nhanh mới đặt buổi tối m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>\"các siêu phẩm thấy cấu hình toàn tựa tựa nhau...</td>\n",
       "      <td>các siêu phẩm thấy cấu_hình toàn tựa tựa nhau ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_000008</td>\n",
       "      <td>0</td>\n",
       "      <td>\"hàng ship nhanh chất lượng tốt tư vấn nhiệt t...</td>\n",
       "      <td>hàng giao hàng nhanh chất_lượng tốt tư_vấn nhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_000009</td>\n",
       "      <td>1</td>\n",
       "      <td>\"đồng hồ đẹp nhưng 1 cái đứt dây 1 cái k chạy ...</td>\n",
       "      <td>đồng_hồ đẹp nhưng 1 cái đứt dây 1 cái không ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID Label                                           Sentence  \\\n",
       "0  train_000000     0  \"dung dc sp tot cam on shop đóng gói sản phẩm ...   \n",
       "1  train_000001     0  \" chất lượng sản phẩm tuyệt vời . son mịn nhưn...   \n",
       "2  train_000002     0  \" chất lượng sản phẩm tuyệt vời nhưng k có hộp...   \n",
       "3  train_000003     1  \":(( mình hơi thất vọng 1 chút vì mình đã kỳ v...   \n",
       "4  train_000004     1  \"lần trước mình mua áo gió màu hồng rất ok mà ...   \n",
       "5  train_000005     0  \" chất lượng sản phẩm tuyệt vời có điều không ...   \n",
       "6  train_000006     0  \"đã nhận đc hàng rất nhanh mới đặt buổi tối mà...   \n",
       "7  train_000007     1  \"các siêu phẩm thấy cấu hình toàn tựa tựa nhau...   \n",
       "8  train_000008     0  \"hàng ship nhanh chất lượng tốt tư vấn nhiệt t...   \n",
       "9  train_000009     1  \"đồng hồ đẹp nhưng 1 cái đứt dây 1 cái k chạy ...   \n",
       "\n",
       "                                        New_Sentence  \n",
       "0  dung được sản_phẩm tốt cám_ơn cửa_hàng đóng_gó...  \n",
       "1  chất_lượng sản_phẩm tuyệt_vời son mịn nhưng kh...  \n",
       "2  chất_lượng sản_phẩm tuyệt_vời nhưng không có h...  \n",
       "3  mình hơi thất_vọng 1 chút vì mình đã kỳ_vọng c...  \n",
       "4  lần trước mình mua áo_gió màu hồng rất ok mà đ...  \n",
       "5  chất_lượng sản_phẩm tuyệt_vời có_điều không cứ...  \n",
       "6  đã nhận được hàng rất nhanh mới đặt buổi tối m...  \n",
       "7  các siêu phẩm thấy cấu_hình toàn tựa tựa nhau ...  \n",
       "8  hàng giao hàng nhanh chất_lượng tốt tư_vấn nhi...  \n",
       "9  đồng_hồ đẹp nhưng 1 cái đứt dây 1 cái không ch...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16087 entries, 0 to 16086\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            16087 non-null  object\n",
      " 1   Label         16087 non-null  object\n",
      " 2   Sentence      16087 non-null  object\n",
      " 3   New_Sentence  16087 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 502.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df.loc[:,'New_Sentence'].values, (train_df.loc[:,'Label'].values).astype('int'), test_size = .2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9108710855544331\n",
      "Test accuracy: 0.8666873834679926\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesModel()\n",
    "clf = model.clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\",clf.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.945139482477271\n",
      "Test accuracy: 0.8912367930391547\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVMModel().clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\",clf_svm.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", clf_svm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input from keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mời bạn nhập bình luận: tuyệt vời đấy nhưng không mua\n",
      "tích cực\n",
      "[[0.71058395 0.28941605]]\n"
     ]
    }
   ],
   "source": [
    "sentiment = ['tích cực', 'tiêu cực']\n",
    "test_data = {}\n",
    "test_data['Sentence']= input('Mời bạn nhập bình luận: ')\n",
    "test_df = pd.DataFrame(test_data,index=[0])\n",
    "predict = clf_svm.predict(test_df['Sentence'])[0]\n",
    "print(sentiment[predict])\n",
    "print(clf_svm.predict_proba(test_df['Sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter error label predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = clf_svm.predict(train_df['New_Sentence'])\n",
    "probability = clf_svm.predict_proba(train_df['New_Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Positive_proba'] = probability[:,0]\n",
    "train_df['Negative_proba'] = probability[:,1]\n",
    "train_df['Predict_label'] = predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_predict_df = train_df[train_df['Label']!= predict_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manhlk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "for i in range(error_predict_df.shape[0]):\n",
    "    length.append(len((error_predict_df['Sentence'][error_predict_df.index[i]]).split()))\n",
    "error_predict_df['Length_sentence'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>New_Sentence</th>\n",
       "      <th>Positive_proba</th>\n",
       "      <th>Negative_proba</th>\n",
       "      <th>Predict_label</th>\n",
       "      <th>Length_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>\" chất lượng sản phẩm tuyệt vời nhưng k có hộp...</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời nhưng không có h...</td>\n",
       "      <td>0.408030</td>\n",
       "      <td>0.591970</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>train_000032</td>\n",
       "      <td>0</td>\n",
       "      <td>\"sạc tự động ngắt pin\"</td>\n",
       "      <td>sạc tự_động ngắt pin</td>\n",
       "      <td>0.149288</td>\n",
       "      <td>0.850712</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>train_000050</td>\n",
       "      <td>1</td>\n",
       "      <td>\" đóng gói sản phẩm rất kémtư vấn k nhiệt tình\"</td>\n",
       "      <td>đóng_gói sản_phẩm rất kémtư vấn không nhiệt_tình</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.174858</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>train_000052</td>\n",
       "      <td>0</td>\n",
       "      <td>\"e xay đá mà bị gãy ko xay dc ạ\"</td>\n",
       "      <td>e xay đá mà bị gãy khôngxay được ạ</td>\n",
       "      <td>0.195948</td>\n",
       "      <td>0.804052</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>train_000057</td>\n",
       "      <td>0</td>\n",
       "      <td>\"sản phẩm k như mình mong đợi..k cài dc đồ chơ...</td>\n",
       "      <td>sản_phẩm không như mình mong_đợi k cài được đồ...</td>\n",
       "      <td>0.262330</td>\n",
       "      <td>0.737670</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15975</th>\n",
       "      <td>train_015975</td>\n",
       "      <td>1</td>\n",
       "      <td>\"mình đặt 5 gói mặt nạ su:m trắng mà shop giao...</td>\n",
       "      <td>mình đặt 5 gói mặt_nạ su m trắng mà cửa_hàng g...</td>\n",
       "      <td>0.601992</td>\n",
       "      <td>0.398008</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15976</th>\n",
       "      <td>train_015976</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"hồi đó mình sài s5, nhưng chạy theo phong tr...</td>\n",
       "      <td>hồi đó mình xài s5 nhưng chạy theo phong_trào ...</td>\n",
       "      <td>0.282036</td>\n",
       "      <td>0.717964</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>train_015993</td>\n",
       "      <td>0</td>\n",
       "      <td>\"như l\"</td>\n",
       "      <td>như l</td>\n",
       "      <td>0.438406</td>\n",
       "      <td>0.561594</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16029</th>\n",
       "      <td>train_016029</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"rất ấn tượng.\"\"</td>\n",
       "      <td>rất ấn_tượng</td>\n",
       "      <td>0.456237</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16036</th>\n",
       "      <td>train_016036</td>\n",
       "      <td>0</td>\n",
       "      <td>\"đỡ lag hơn 9.3.1 nhiều mà...\"</td>\n",
       "      <td>đỡ lag hơn 9 3 1 nhiều mà</td>\n",
       "      <td>0.535259</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID Label                                           Sentence  \\\n",
       "2      train_000002     0  \" chất lượng sản phẩm tuyệt vời nhưng k có hộp...   \n",
       "32     train_000032     0                             \"sạc tự động ngắt pin\"   \n",
       "50     train_000050     1    \" đóng gói sản phẩm rất kémtư vấn k nhiệt tình\"   \n",
       "52     train_000052     0                   \"e xay đá mà bị gãy ko xay dc ạ\"   \n",
       "57     train_000057     0  \"sản phẩm k như mình mong đợi..k cài dc đồ chơ...   \n",
       "...             ...   ...                                                ...   \n",
       "15975  train_015975     1  \"mình đặt 5 gói mặt nạ su:m trắng mà shop giao...   \n",
       "15976  train_015976     0  \"\"hồi đó mình sài s5, nhưng chạy theo phong tr...   \n",
       "15993  train_015993     0                                            \"như l\"   \n",
       "16029  train_016029     0                                  \"\"rất ấn tượng.\"\"   \n",
       "16036  train_016036     0                     \"đỡ lag hơn 9.3.1 nhiều mà...\"   \n",
       "\n",
       "                                            New_Sentence  Positive_proba  \\\n",
       "2      chất_lượng sản_phẩm tuyệt_vời nhưng không có h...        0.408030   \n",
       "32                                  sạc tự_động ngắt pin        0.149288   \n",
       "50      đóng_gói sản_phẩm rất kémtư vấn không nhiệt_tình        0.825142   \n",
       "52                    e xay đá mà bị gãy khôngxay được ạ        0.195948   \n",
       "57     sản_phẩm không như mình mong_đợi k cài được đồ...        0.262330   \n",
       "...                                                  ...             ...   \n",
       "15975  mình đặt 5 gói mặt_nạ su m trắng mà cửa_hàng g...        0.601992   \n",
       "15976  hồi đó mình xài s5 nhưng chạy theo phong_trào ...        0.282036   \n",
       "15993                                              như l        0.438406   \n",
       "16029                                       rất ấn_tượng        0.456237   \n",
       "16036                          đỡ lag hơn 9 3 1 nhiều mà        0.535259   \n",
       "\n",
       "       Negative_proba  Predict_label  Length_sentence  \n",
       "2            0.591970              1               19  \n",
       "32           0.850712              1                5  \n",
       "50           0.174858              0               11  \n",
       "52           0.804052              1               10  \n",
       "57           0.737670              1               18  \n",
       "...               ...            ...              ...  \n",
       "15975        0.398008              0               15  \n",
       "15976        0.717964              1               99  \n",
       "15993        0.561594              1                2  \n",
       "16029        0.543763              1                3  \n",
       "16036        0.464741              1                6  \n",
       "\n",
       "[1056 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.export_to_excel(error_predict_df,'error_data','False predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>New_Sentence</th>\n",
       "      <th>Positive_proba</th>\n",
       "      <th>Negative_proba</th>\n",
       "      <th>Predict_label</th>\n",
       "      <th>Length_sentence</th>\n",
       "      <th>ReLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>\" chất lượng sản phẩm tuyệt vời nhưng k có hộp...</td>\n",
       "      <td>chất_lượng sản_phẩm tuyệt_vời nhưng không có h...</td>\n",
       "      <td>0.405822</td>\n",
       "      <td>0.594178</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>train_000032</td>\n",
       "      <td>0</td>\n",
       "      <td>\"sạc tự động ngắt pin\"</td>\n",
       "      <td>sạc tự_động ngắt pin</td>\n",
       "      <td>0.235148</td>\n",
       "      <td>0.764852</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>train_000050</td>\n",
       "      <td>1</td>\n",
       "      <td>\" đóng gói sản phẩm rất kémtư vấn k nhiệt tình\"</td>\n",
       "      <td>đóng_gói sản_phẩm rất kémtư vấn không nhiệt_tình</td>\n",
       "      <td>0.832132</td>\n",
       "      <td>0.167868</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>train_000052</td>\n",
       "      <td>0</td>\n",
       "      <td>\"e xay đá mà bị gãy ko xay dc ạ\"</td>\n",
       "      <td>e xay đá mà bị gãy không xay được ạ</td>\n",
       "      <td>0.058185</td>\n",
       "      <td>0.941815</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>train_000057</td>\n",
       "      <td>0</td>\n",
       "      <td>\"sản phẩm k như mình mong đợi..k cài dc đồ chơ...</td>\n",
       "      <td>sản_phẩm không như mình mong_đợi k cài được đồ...</td>\n",
       "      <td>0.195521</td>\n",
       "      <td>0.804479</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            ID  Label  \\\n",
       "0           2  train_000002      0   \n",
       "1          32  train_000032      0   \n",
       "2          50  train_000050      1   \n",
       "3          52  train_000052      0   \n",
       "4          57  train_000057      0   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  \" chất lượng sản phẩm tuyệt vời nhưng k có hộp...   \n",
       "1                             \"sạc tự động ngắt pin\"   \n",
       "2    \" đóng gói sản phẩm rất kémtư vấn k nhiệt tình\"   \n",
       "3                   \"e xay đá mà bị gãy ko xay dc ạ\"   \n",
       "4  \"sản phẩm k như mình mong đợi..k cài dc đồ chơ...   \n",
       "\n",
       "                                        New_Sentence  Positive_proba  \\\n",
       "0  chất_lượng sản_phẩm tuyệt_vời nhưng không có h...        0.405822   \n",
       "1                               sạc tự_động ngắt pin        0.235148   \n",
       "2   đóng_gói sản_phẩm rất kémtư vấn không nhiệt_tình        0.832132   \n",
       "3                e xay đá mà bị gãy không xay được ạ        0.058185   \n",
       "4  sản_phẩm không như mình mong_đợi k cài được đồ...        0.195521   \n",
       "\n",
       "   Negative_proba  Predict_label  Length_sentence  ReLabel  \n",
       "0        0.594178              1               19        2  \n",
       "1        0.764852              1                5        1  \n",
       "2        0.167868              0               11        1  \n",
       "3        0.941815              1               10        1  \n",
       "4        0.804479              1               18        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relabel_error_df = pd.read_excel(r'C:\\Users\\MANHLK\\Documents\\Machine_Learning\\Sentiment\\error_predict.xlsx')\n",
    "relabel_error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    611\n",
       " 0    200\n",
       " 2    188\n",
       "-1    111\n",
       "Name: ReLabel, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sentiment = pd.value_counts(relabel_error_df['ReLabel'])\n",
    "count_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(relabel_error_df.shape[0]):\n",
    "    relabel = relabel_error_df['ReLabel'][i]\n",
    "    if relabel == 2 or relabel == -1:\n",
    "        relabel = np.random.randint(0,2)\n",
    "        train_df['Label'][relabel_error_df.iloc[:,0].values[i]] = relabel\n",
    "    else:\n",
    "        train_df['Label'][relabel_error_df.iloc[:,0].values[i]] = relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.export_to_excel(train_df,'train','Sheet 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16087 entries, 0 to 16086\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ID            16087 non-null  object\n",
      " 1   Label         16087 non-null  object\n",
      " 2   Sentence      16087 non-null  object\n",
      " 3   New_Sentence  16087 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 502.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SVM Model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df.loc[:,'New_Sentence'].values, (train_df.loc[:,'Label'].values).astype('int'), test_size = .2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9759111042039008\n",
      "Test accuracy: 0.9403356121814792\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVMModel().clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\",clf_svm.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", clf_svm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aivivn = train_df[['Label', 'Sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.export_to_excel(data_aivivn,'data_aivivn','Sheet_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
