{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(r'Data\\data_aivivn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8882\n",
       "1    7205\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sentiment = pd.value_counts(train['Label'])\n",
    "count_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    \n",
    "    # chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Xóa icon\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                   u\"\\U00002702-\\U000027B0\"\n",
    "                   u\"\\U000024C2-\\U0001F251\"\n",
    "                   u\"\\U0001f926-\\U0001f937\"\n",
    "                   u\"\\u200d\"\n",
    "                   u\"\\u2640-\\u2642\" \n",
    "                   \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Chuan hoa tieng viet, tieng anh, thuat ngu\n",
    "    replace_list={\n",
    "        'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n",
    "    'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n",
    "    'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
    "    'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
    "    'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
    "    #Chuẩn hóa 1 số sentiment words/English words\n",
    "    ':))': '  positive ', ':)': ' positive ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n",
    "    'okey': ' ok ', 'ôkê': ' ok ', ' oki ': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n",
    "    ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ', 'cam on':u'cám ơn',u'cảm ơn':'cám ơn',\n",
    "    ' not ': u' không ',' khoong ': ' không ', u' kg ': u' không ','ko ': 'không', ' k ': u' không ',' kh ':u' không ',' kô ':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', ' ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',' k ':u' không ',u'chẳng':u'không',u'đéo':u'không',\n",
    "    'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
    "    ' lol ': ' negative ',' cc ': ' negative ','cute': u' dễ thương ','huhu': ' negative ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', ' j ': u' gì ', '“': ' ',\n",
    "    ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
    "    'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u' positive ', 'store': u' cửa hàng ',\n",
    "    'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n",
    "    'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n",
    "    'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
    "    'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n",
    "    'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n",
    "    'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n",
    "    'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n",
    "    'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ', ' quả ng ': ' quảng ',\n",
    "    'dep': u' đẹp ',u'xầu':u'xấu',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u' qủa': u' quả', \n",
    "    ' iu ': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời', '><': u' positive ', \n",
    "    ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback ',\n",
    "    'qc':u'quảng cáo',u' éo ':' negative ',' bik ':' biết ',\n",
    "    #dưới 3* quy về 1*, trên 3* quy về 5*\n",
    "    '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ', '5 sao': '5star',\n",
    "    'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ', '3 sao':'5star','4 sao':'5star','1 sao':'1star',\n",
    "    '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ','1*':' 1star ', '2*':' 1star ','3*':' 5star ','4*':' 5star ','5*':' 5star '\n",
    "    }\n",
    "    for k, v in replace_list.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    #Xóa dấu câu\n",
    "    text = re.sub('['+string.punctuation+']', ' ', text)\n",
    "\n",
    "    # Tokenizer\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Sentence = []\n",
    "for i in range(train.shape[0]):\n",
    "    New_Sentence.append(pre_processing(train['Sentence'][i]))\n",
    "train['New_Sentence'] = New_Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.loc[:,'New_Sentence'].values, train.loc[:,'Label'].values, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12869,)\n",
      "(12869,)\n",
      "(3218,)\n",
      "(3218,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo Tokenizer\n",
    "tokenizer = Tokenizer(num_words= vocab_size, oov_token= oov_tok)\n",
    "\n",
    "# Đưa từ vào tokenizer để tạo từ điển\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Biến các câu train thành sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# Padding cho các train sequences\n",
    "X_train = pad_sequences(X_train, maxlen= max_length, padding=padding_type, truncating= trunc_type)\n",
    "\n",
    "# Biến các câu test thành sequences tương ứng\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen= max_length, padding=padding_type, truncating= trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12869, 100)\n",
      "(3218, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_dim))\n",
    "model1.add(SimpleRNN(32))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                3104      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 643,649\n",
      "Trainable params: 643,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "403/403 [==============================] - 11s 27ms/step - loss: 0.6341 - accuracy: 0.6261 - val_loss: 0.5783 - val_accuracy: 0.6917\n",
      "Epoch 2/10\n",
      "403/403 [==============================] - 9s 23ms/step - loss: 0.5157 - accuracy: 0.7233 - val_loss: 0.6117 - val_accuracy: 0.6336\n",
      "Epoch 3/10\n",
      "403/403 [==============================] - 10s 24ms/step - loss: 0.4574 - accuracy: 0.7835 - val_loss: 0.5563 - val_accuracy: 0.7045\n",
      "Epoch 4/10\n",
      "403/403 [==============================] - 12s 30ms/step - loss: 0.4252 - accuracy: 0.8110 - val_loss: 0.5563 - val_accuracy: 0.7237\n",
      "Epoch 5/10\n",
      "403/403 [==============================] - 13s 32ms/step - loss: 0.4131 - accuracy: 0.8214 - val_loss: 0.5263 - val_accuracy: 0.7505\n",
      "Epoch 6/10\n",
      "403/403 [==============================] - 11s 28ms/step - loss: 0.4368 - accuracy: 0.8113 - val_loss: 0.6828 - val_accuracy: 0.5864\n",
      "Epoch 7/10\n",
      "403/403 [==============================] - 12s 29ms/step - loss: 0.5947 - accuracy: 0.6857 - val_loss: 0.5800 - val_accuracy: 0.6998\n",
      "Epoch 8/10\n",
      "403/403 [==============================] - 12s 31ms/step - loss: 0.4864 - accuracy: 0.7719 - val_loss: 0.5915 - val_accuracy: 0.7057\n",
      "Epoch 9/10\n",
      "403/403 [==============================] - 9s 23ms/step - loss: 0.4608 - accuracy: 0.7889 - val_loss: 0.5435 - val_accuracy: 0.7377\n",
      "Epoch 10/10\n",
      "403/403 [==============================] - 9s 23ms/step - loss: 0.4020 - accuracy: 0.8270 - val_loss: 0.5470 - val_accuracy: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2da3510a080>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                3104      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 643,649\n",
      "Trainable params: 643,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, embedding_dim, input_length=X_train.shape[1]))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "403/403 [==============================] - 9s 24ms/step - loss: 0.1846 - accuracy: 0.9420 - val_loss: 0.4416 - val_accuracy: 0.8428\n",
      "Epoch 2/5\n",
      "403/403 [==============================] - 9s 22ms/step - loss: 0.1721 - accuracy: 0.9444 - val_loss: 0.4197 - val_accuracy: 0.8505\n",
      "Epoch 3/5\n",
      "403/403 [==============================] - 10s 24ms/step - loss: 0.1279 - accuracy: 0.9608 - val_loss: 0.4350 - val_accuracy: 0.8564\n",
      "Epoch 4/5\n",
      "403/403 [==============================] - 9s 23ms/step - loss: 0.1300 - accuracy: 0.9601 - val_loss: 0.4109 - val_accuracy: 0.8599\n",
      "Epoch 5/5\n",
      "403/403 [==============================] - 9s 23ms/step - loss: 0.1139 - accuracy: 0.9639 - val_loss: 0.4952 - val_accuracy: 0.8415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2da34c2df28>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
